services:
  kafka1:
    image: apache/kafka:latest
    container_name: kafka-container1
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-container1:9092
      KAFKA_LISTENERS: PLAINTEXT://kafka-container1:9092,CONTROLLER://kafka-container1:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-container1:9093,2@kafka-container2:9095
      KAFKA_LOG_DIRS: /var/lib/kafka/data1
    ports:
      - "9092:9092"
      - "9093:9093"
    networks:
      - myNetwork
    volumes:
      - .:/app

  kafka2:
    image: apache/kafka:latest
    container_name: kafka-container2
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-container2:9094
      KAFKA_LISTENERS: PLAINTEXT://kafka-container2:9094,CONTROLLER://kafka-container2:9095
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-container1:9093,2@kafka-container2:9095
      KAFKA_LOG_DIRS: /var/lib/kafka/data2
    ports:
      - "9094:9094"
      - "9095:9095"
    networks:
      - myNetwork
    volumes:
      - .:/app

  kafka-connect:
    image: confluentinc/cp-kafka-connect:latest
    container_name: kafka-connect
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka-container1:9092,kafka-container2:9094
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_GROUP_ID: connect-cluster
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-statuses
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CONNECT_PLUGIN_PATH: /usr/share/java
    depends_on:
      - kafka1
      - kafka2
    networks:
      - myNetwork
    volumes:
      - .:/app

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: LocalCluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-container1:9092,kafka-container2:9094
      KAFKA_CLUSTERS_0_ZOOKEEPER: dummy:2181 # Not used with KRaft, but required
    depends_on:
      - kafka1
      - kafka2
    networks:
      - myNetwork
    volumes:
      - .:/app

  mysql:
    image: mysql:8.0
    container_name: mysql-container
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: testdb
    ports:
      - "3306:3306"
    command: --default-authentication-plugin=mysql_native_password --binlog-format=ROW --server-id=1
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 10s
      retries: 5
    networks:
      - myNetwork
    volumes:
      - .:/app

  cassandra:
    image: cassandra:latest
    container_name: cassandra-container
    ports:
      - "9042:9042"
    networks:
      - myNetwork
    volumes:
      - .:/app
   
  python:
    image: python:3.12-slim
    container_name: python-service
    command: sleep infinity  # Keeps the container running
    volumes:
      - .:/app
    working_dir: /app
    networks:
      - myNetwork
      
  hdfs-datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: hdfs-datanode
    networks:
      - myNetwork
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://hdfs-container:8020
      - HDFS_CONF_dfs_datanode_data_dir=/hadoop/dfs/data
    volumes:
      - hdfs_datanode_data:/hadoop/dfs/data
    depends_on:
      - hdfs-namenode
  
  hdfs-namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: hdfs-container
    networks:
      - myNetwork
    ports:
      - "50070:50070"  # Web UI
      - "9000:9000"  # NameNode RPC
    environment:
      - CLUSTER_NAME=hdfs-test-cluster 
    volumes:
      - hdfs_namenode_data:/hadoop/dfs/name   # store HDFS metadata properly
      

volumes:
  hdfs_namenode_data:
  hdfs_datanode_data:
  
networks:
  myNetwork:
    external: true

